#!/usr/bin/perl -w
# $Id$
use strict;
require v5.10.0;
our $VERSION = 'v0.3';

BEGIN
{
    my $PROGRAM_DIR = $0;
    $PROGRAM_DIR =~ s/[^\/\\]+$//;
    $PROGRAM_DIR = "./" unless($PROGRAM_DIR);
    unshift @INC, 
        map "$PROGRAM_DIR$_",qw{modules lib ../modules ..lib};
}

my %OPTS;
my @OPTIONS = qw/
                help|h|? version|ver edit-me manual|man
                autoname|a cookie|b=s directory|d ext|e=s 
                fullname|f logger|L=s maxtime|M=i maxtask|m=i
                taskname|n=s referer|r=s workdir|w=s urlhist|U
                no-clobber|nc|c numlen|i=i
              /;

if(@ARGV)
{
    require Getopt::Long;
    require MyPlace::Usage;
    Getopt::Long::Configure('no_ignore_case');
    Getopt::Long::GetOptions(\%OPTS,@OPTIONS);
    MyPlace::Usage::Process(\%OPTS,$VERSION);
}

use MyPlace::ParallelRun;
use URI::Escape;
use MyPlace::Script::Message;


my $def_mul=3;
my $createdir = $OPTS{"directory"} ? $OPTS{"directory"} : 0;
my $maxtime = $OPTS{"maxtime"} ? $OPTS{"maxtime"} : undef;
my $muldown   = $OPTS{"maxtask"} ? $OPTS{"maxtask"} : $def_mul;
my $taskname  = $OPTS{"taskname"} ? $OPTS{"taskname"} : "";
my $autoname  = $OPTS{"autoname"} ? $OPTS{"autoname"} : 0;
my $extname   = $OPTS{"ext"} ? $OPTS{"ext"} : "";
my $workdir   = $OPTS{"workdir"} ? $OPTS{"workdir"} : "";
my $refer     = $OPTS{"referer"} ? $OPTS{"referer"} : "";
my $logger    = $OPTS{"logging"} ? $OPTS{"logging"} : "";
my $cookie    = $OPTS{"cookie"} ? $OPTS{"cookie"} : "";
my $number    = $OPTS{"numlen"} ? $OPTS{"numlen"} : "";
my $fullname  = $OPTS{"fullname"} ? 1 : 0;
my $urlhist   = $OPTS{'urlhist'} ? 1 : 0;
my $URL_DATABASE_FILE = 'URLS.txt';
my %Local_Map;

$autoname="true" if($number);
unless($taskname) {
    $taskname = shift(@ARGV)  if(@ARGV);
}
$taskname = "" unless($taskname);
$muldown = 1 if( $muldown<1);

#if($workdir) {
#    mkdir $workdir unless(-d $workdir);
#    $workdir .= "/" unless($workdir =~ /\/$/);
#    chdir($workdir);
#}

my %URL_DATABASE;

sub load_database {
    open FI,"<",$URL_DATABASE_FILE or return;
    while(<FI>) {
        chomp;
        $URL_DATABASE{$_}=1;
    }
    close FI;
}
sub check_database {
    my $url = shift;
    if($URL_DATABASE{$url}) {
#        use Data::Dumper;
#        print STDERR Data::Dumper->Dump([\%URL_DATABASE],['*URL_DATABASE']),"\n";
#        die($url);
        return 1;
    }
    else {
        $URL_DATABASE{$url}=1;
        return undef;
    }
}
sub save_database {
    open FO,">",$URL_DATABASE_FILE or return;
    foreach (keys %URL_DATABASE) {
        print FO $_,"\n";
    }
    close FO;
}
sub Uniqname($) {
    my $ext =shift;
    my $max = 10000000000;
    my $result;
    do { 
        my $n1 = int (rand($max));
        my $n2 = log($max / $n1)/log(10);
        $result=$n1 . "0"x$n2 . $ext;
    } until (! -f $result);
    return $result;
}
sub GetFilename_Fullname {
    my $result=shift;
    $result =~ s/^.*:\/\///;
    $result =~ s/[\/\?\:\\\*\&]/_/g;
    $result =~ s/&//g;
    return $result;
}

sub GetFilename_Auto {
    my $URL=shift;
    my $num=shift;
    my $result;
    #my $ext=$extname;
    #($ext=$URL) =~ s/^.*\.([^\.]*)$/.$1/ unless($ext);
    #$result=$num ? "$num$ext" : Uniqname($ext);
    $result = $URL;
    $result =~ s/^.*:\/\///;
    $result =~ s/[\/\?\:\\\*\&]/_/g;
    $result =~ s/&//g;
    if(length($result)>=128) {
        $result = substr($result,0,127);
    }
    $result = "$num.$result" if(defined $num);
    if($createdir) {
        my $dirname=$URL;
        $dirname =~ s/^.*:\/*[^\/]*\///;
        $dirname =~ s/\/[^\/]*//;
        $dirname .= "/" if($dirname);
        $result = $dirname . $result;    
    }
    return $result;
}
sub GetFilename_NoAuto {
    my $result=shift;
    if($createdir) {
        $result =~ s/^.*:\/*[^\/]*\///;
    }
    else {
        $result =~ s/^.*\///;
    }
    return $result;
}

sub pushArgPair(\@$$) {
    my $DARG=shift;
    my $key=shift;
    my $value=shift;
    if($value) {
        push @{$DARG},$key;
        push @{$DARG},$value;
    }
}

my %record;
sub inqueue {
    my ($URL,$index,$count,$prefix)=@_;
    my $curname= "[$prefix$index/$count]";
    my $stridx = "0" x (length($count)-length($index)+1) . $index if($number);
    if($record{$URL}) {
        app_warning($curname . "Duplicated, $URL [Ignored]\n");
        return undef;
    }
    $record{$URL} = 1;
    my $filename =
            $Local_Map{$URL} ? 
                $Local_Map{$URL} 
            : $fullname ? 
                GetFilename_Fullname($URL) 
                #GetFilename_Fullname(uri_unescape($URL)) 
            : $autoname ? 
                GetFilename_Auto($URL,$stridx) 
                #GetFilename_Auto(uri_unescape($URL),$stridx) 
            : GetFilename_NoAuto($URL);

    if($OPTS{"no-clobber"}) {
        if(-f $workdir . $filename) {
            app_warning($curname . "$URL\t[Ignored, TARGET EXISTS]\n");
            return undef;
        }
    }

    my $thisrefer= $refer ? $refer : $URL;
    if($logger) {system($logger,$filename,$URL);}
    my @DARG;
    pushArgPair(@DARG,"-u",$URL);
    pushArgPair(@DARG,"-s",$filename);
    #pushArgPair(@DARG,"-s",$workdir . $filename);
    pushArgPair(@DARG,"-n",$curname);
    pushArgPair(@DARG,"-r",$thisrefer);
    pushArgPair(@DARG,"-b",$cookie);
    pushArgPair(@DARG,"-m",$maxtime);
    push(@DARG,"-d");
    para_queue "download",@DARG;
    return 1;
}


my $prefix = $taskname ? $taskname . " " : "";
my @URLS;
my $index=0;
my $count=0;


sub set_workdir {
    my $w = shift;
    return undef unless($w);
    if(! -d $w) {
        system("mkdir","-p","--",$w) and die("$!\n");
    }
    chdir $w or die("$!\n");
    return $w;
}

use Cwd;
my $PWD;
if($workdir) {
    set_workdir($workdir);
}
$PWD = getcwd;

if($cookie) {
    system("mkcookie '$cookie' >download.cookie");
    $cookie="download.cookie";
}

load_database() if($urlhist);
para_init $muldown;
my $no_urls_count=0;
while(<STDIN>) {
    chomp;
    s/^\s+//;
    s/\s+$//;
    if(!$_) {
        next;
    }
    elsif($_ =~ m/^#BATCHGET:/) {
        $no_urls_count++;
        push @URLS,$_;
        $count++;
        next;
    }
    elsif($_ =~ /([^\t]+)\t+([^\t]+)/) {
        $Local_Map{$1} = $2;
        $_ = $1;
        $Local_Map{$_} =~ s/^(http|ftp|https):?\/*//gi;
        $Local_Map{$_} =~ s/[\/:,\?\*\\]/_/g;
    }

    if(check_database($_)) {
        app_warning("[Ignored, In DATABASE]$_\n");
        next;
    }
    #if($urlhist) {
    #    next if $is_old;
    #};
    #my $is_old = check_database($_);
    #if($urlhist and $is_old) {
    #     app_warning("$_\t[Ingored, IN DATABASE]\n");
    #    next;
    #}
    #check_database($_));
    push @URLS,$_;
    $count++;
    #if(0 and &para_isfree()) { # disable pre processing! (08/03/2010 xiaoranzzz@gmail.com)
    #    my $URL = shift @URLS;
    #    $index++;
    #    &inqueue($URL,$index,$count,$prefix);
    #}
#    print STDERR ("\r$count URLS enqueued...                 ");
}
$count = $count - $no_urls_count;
foreach(@URLS) {
    if(m/^#BATCHGET:chdir:(.+)$/) {
        my $w = $1;
        $w =~ s/[:\?\*]+//g;
        if($w) {
            app_message('Change working directory to ' . "$w\n");
            chdir $PWD or die("$!\n");
            set_workdir($w);
        }
    }
    else {
        $index++;
        if(inqueue($_,$index,$count,$prefix)) {
            sleep 1;
        }
    }
}
chdir $PWD;
#or die("$!\n");
para_cleanup();
save_database() if($urlhist);

#print STDERR ("\n");
#exit 0 unless($count);



__END__

=pod

=head1  NAME

batchget - A batch mode downloader

=head1  SYNOPSIS

batchget [options] ...

cat url.lst | batchget

cat url.lst | batchget -a -d 

=head1  OPTIONS

=over 12

=item B<-a,--autoname>

Use indexing of URLs as output filename 

=item B<-b,--cookie>

Use cookie jar

=item B<-c,--nc,--no-clobber>

No clobber when target exists.

=item B<-d,--directory>

Create directories

=item B<-e,--ext>

Extension name for autonaming

=item B<-f,--fullname>

Use URL as output filename

=item B<-i,--numlen>

Number length for index filename

=item B<-M,--maxtime>

Max time for a single download process

=item B<-m,--maxtask>

Max number of simulatanous downloading task

=item B<-n,--taskname>

Task name

=item B<-r,--referer>

Global referer URL

=item B<-w,--workdir>

Global working directory

=item B<-U,--urlhist>

Use URL downloading history databasa

=item B<--version>

Print version infomation.

=item B<-h>,B<--help>

Print a brief help message and exits.

=item B<--manual>,B<--man>

View application manual

=item B<--edit-me>

Invoke 'editor' against the source

=back

=head1  DESCRIPTION

A downloader which can download multiple urls at the same time and/or in queue.

=head1  CHANGELOG

    2007-10-28  xiaoranzzz  <xiaoranzzz@myplace.hell>
    
        * file created, version 0.1

    2010-08-03  xiaoranzzz  <xiaoranzzz@myplace.hell>
        
        * update to version 0.2

=head1  AUTHOR

xiaoranzzz <xiaoranzzz@myplace.hell>

=cut


